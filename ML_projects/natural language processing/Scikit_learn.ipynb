{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit-learn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('pdf', 'svg')"
      ],
      "metadata": {
        "id": "6n9E5CwOd4ox"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anotações primeiro contato com sklearn (scikit.learn)\n"
      ],
      "metadata": {
        "id": "otoiFBcBXYYS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phTLBi_nRy7v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fresh Start: \n",
        "\n",
        "* https://archive.ics.uci.edu/ml/index.php \n",
        "> Repositório aberto com datasets que podem ser usados para treinar ML, praticar e como propósitos didáticos - sempre que possível, podemos utilizar esse site como base para os projetos que quisermos executar ou postagens em formato de blog.\n",
        "\n",
        "Nesse notebook, vamos trabalhar um projeto envolvendo o dataset da UCI: \n",
        "[Car Evaluation Data Set](https://archive.ics.uci.edu/ml/datasets/Car+Evaluation) \n",
        "\n",
        "Todavia, vamos rodar algumas celulas antes com diversos outros datasets, tanto do UCI quando amostras para teste da própria scikit.learn no intuito ne nos aprofundarmos mais com a lib skilearn.\n",
        "\n",
        "Antes de escrevermos algo, dessa vez vamos atentar a como salvar um modelo já treinado e reutilizar ele em outras run's (vide o projeto de aprendizagem de texto que fiz anteriormente, que ficou claro o quanto demora para treinar e rodar um modelo por si só- principalmente sem uma GPU muito eficiente) \n",
        "\n"
      ],
      "metadata": {
        "id": "YmYshoK4U7AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiramente importar esse modulo\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "#Digamos que a run do modelo seja\n",
        "clf.fit = (X_train, y_train)\n",
        "\n",
        "#após treinar o modelo, fazemos: \n",
        "filename = 'model.sav'\n",
        "joblib.dump(clf,filename)\n",
        "\n",
        "#da próxima vez que for rodar o modelo, del no save.script e roda\n",
        "clf = joblib.load(filename)  "
      ],
      "metadata": {
        "id": "kSBNOKcOWQ5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split de treino: \n",
        "\n",
        "Dado um dataset (100% dos dados que temos disponíveis) Podemos usar alguns métodos para utilizar esses dados não só para treinar nosso modelo, mas também para testar a acurácia do mesmo. Para isso, reservamos alguma quantidade específica no nosso sampling para verificar como o predict do nosso modelo infere algo corretamente sobre eles antes de ter conhecimento dos mesmos.\n"
      ],
      "metadata": {
        "id": "KhVaLdducZEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "#split in features and labels\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiOQPevWcoDt",
        "outputId": "d76df48f-99a0-4af7-80dd-98ec4d30e1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4)\n",
            "(150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hours of study vs good/bad grades\n",
        "#10 diff students\n",
        "#train with 8 students\n",
        "#predict with remaining 2\n",
        "#level of accuracy ^^\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) #definindo o grupo de teste como 20% do dataset\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ8-cRmrd3uN",
        "outputId": "fb2adefb-d479-4f92-ae37-7199bf401b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4)\n",
            "(30, 4)\n",
            "(120,)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NNC: method - Nearest Neighbors Classification\n",
        "\n",
        "\n",
        "- Tem interesse em visualizar o que estamos falando nessa sessão? rode `/spyder/programs/knn_iris_classifier.py`\n",
        "\n",
        "\"O algoritmo KNN assume que coisas semelhantes existem nas proximidades. Em outras palavras, coisas semelhantes estão próximas umas das outras.\"\n",
        "\n",
        "\n",
        "\n",
        "como calcula a proximidade de uma N dimensão? Existem várias técnicas para o cálculo da distância\n",
        "\n",
        "* Euclidean\n",
        "\n",
        "* Hamming\n",
        "\n",
        "* Manhattan\n",
        "\n",
        "* Mahalanobis\n",
        "\n",
        "* Minkowski\n",
        "\n",
        "A mais utilizada é a distância Euclidiana, e uma ótima maneira de explicar ela é utilizar a distância Manhattan para exemplificar a diferença entre elas.\n",
        "\n",
        "A **distância euclidiana** representa a distância mais curta entre dois pontos. A **distância de Manhattan** é a soma das diferenças absolutas entre os pontos em todas as dimensões.\n",
        "\n",
        "A **distância de Hamming** calcula a distância entre dois vetores binários. Essa técnica acaba sendo uma boa opção para casos de variáveis categóricas (one-hot).\n",
        "\n",
        "A **distância de Mahalanobis** é a distância entre dois pontos no espaço multivariado. Em caso de variáveis não correlacionadas a distância Euclidiana acaba resultando a mesma coisa que a distância Mahalanobis. Porém quando temos mais de duas variáveis correlacionadas, pode se tornar impossível traçar a distância entre eles com um única reta. \n",
        "\n",
        "#### Hiperparâmetros da função KNN\n",
        "\n",
        "* **N-neighbourd** > número de vizinhos a serem considerados\n",
        "\n",
        "* **Algoritmo** > A opções ‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’ são algoritmos disponíveis para calcular o vizinho mais próximo. A opção ’auto’ deixa a cargo do algoritmo escolher qual tecnica é a mais adequada para aquele determinado problema, olhando para o resultado obtido nas observações anteriores. Já o algoritmo ’ball_tree’, é aconselhável utilizar para problemas com grande número de dimensões, diferente do ‘kd_tree’. Em contrapartida, o custo computacional é maior. A vantage do ‘kd_tree’ é em cima do ‘brute’ em problemas BigData com muitas observações, já que ele utiliza o conhecimento prévio adquirido das distâncias anteriores para inferir. A ideia básica é que se o ponto A está muito distante do ponto B e o ponto B está muito próximo do ponto C, então sabemos que os pontos A — C estão muito distantes, sem ter que calcular explicitamente sua distância. E por fim, ’brute’ calcula a distância de todos os pontos possíveis.\n",
        "\n",
        "* **Leaf size** > Quanto maior, mais rápido será o processamento pois os grupos de amostras serão grande o suficiente para formação de poucos nós. O momento que você precisa se preocupar com esse parâmetro é quando o conjunto de dados é muito grande e o algoritmo escolhido for ’brute’. Seu valor de amostra default é 30.\n",
        "\n",
        "* **p** > 1 ativa a utilização da distância de Manhattan e 2 da distância Euclidiana. Caso não seja inserido nenhum input, distância de minkowski será ativada que é a generalização das distâncias de Manhattan e Euclidiana.\n",
        "\n",
        "* **Metric** > Esse parâmetro escolhemos o tipo de distância que mais se adequa para o problema em questão. O site do scikit-learn tem ótimas tabelas para ilustrar as medidas de distância e o tipo de problema que são utilizadas.\n",
        "\n",
        "* **Weight** > é o inverso da distância que pode ser configurado de três maneiras: ‘uniform’, ‘distance’ e callable. Uniform usa o mesmo pedo para todas os vizinhos. Distance já atribui pesos maiores para os vizinhos mais próximos. Por fim, callable você incorpora uma função em específico.\n",
        "\n",
        "Referências e mais detalhes: \n",
        "- https://medium.com/data-hackers/knn-k-nearest-neighbor-o-que-%C3%A9-aeebe0f833eb\n",
        "\n",
        "- https://link.springer.com/article/10.1007/s42452-019-1329-z\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/neighbors.html#neighbors\n",
        "\n",
        "Vamos agora usar o que aprendemos até aqui como prometido aplicado no dataset da avaliação de carros da UCI. Para isso, vamos usar as seguintes linhas em nosso código, além das bibliotecas exportadas: \n",
        "\n",
        "```Python \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/content/drive/My Drive/file.txt')\n",
        "```\n",
        "\n",
        "Isso  irá pedir para abrir um URL que autorizará a montagem para esse notebook depois de copiar e colar o token de onde você salvará o arquivo baixado com o \"car.data\" no seu drive.\n",
        "\n",
        "Vamos testar a leitura do arquivo:"
      ],
      "metadata": {
        "id": "v6ZWewxOf7FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import neighbors, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/car.data')\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "4YVO7IGBil00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ca5935-d2b1-48f9-aa6d-3dfc5e03cfb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "  buying  maint doors persons lug_boot safety  class\n",
            "0  vhigh  vhigh     2       2    small    low  unacc\n",
            "1  vhigh  vhigh     2       2    small    med  unacc\n",
            "2  vhigh  vhigh     2       2    small   high  unacc\n",
            "3  vhigh  vhigh     2       2      med    low  unacc\n",
            "4  vhigh  vhigh     2       2      med    med  unacc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após printar o dataframe.head() com pandas, notei que o arquivo não tinha título em suas colunas, então abri o car.data no meu pc como um .txt no bloco de notas e adicionei um titulo para cada uma das colunas e printei o dataframe.head() novamente como como ficou acima.\n",
        "\n",
        "Prosseguindo então para os nossos testes"
      ],
      "metadata": {
        "id": "mujo-csy2oUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LABELING OUR DATA\n",
        "X = data[[\n",
        "     'buying',\n",
        "     'maint',\n",
        "     'safety'     \n",
        "]].values\n",
        "\n",
        "y = data[['class']]\n",
        "print(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzYPCgFledl4",
        "outputId": "89b78887-7a83-42a6-d39e-81bf7e80acb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['vhigh' 'vhigh' 'low']\n",
            " ['vhigh' 'vhigh' 'med']\n",
            " ['vhigh' 'vhigh' 'high']\n",
            " ...\n",
            " ['low' 'low' 'low']\n",
            " ['low' 'low' 'med']\n",
            " ['low' 'low' 'high']]       class\n",
            "0     unacc\n",
            "1     unacc\n",
            "2     unacc\n",
            "3     unacc\n",
            "4     unacc\n",
            "...     ...\n",
            "1723   good\n",
            "1724  vgood\n",
            "1725  unacc\n",
            "1726   good\n",
            "1727  vgood\n",
            "\n",
            "[1728 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#REARANGING OUR DATA\n",
        "#converting the data(X) > LabelEncoder transf labels into numbers\n",
        "\n",
        "Le = LabelEncoder()\n",
        "for i in range(len(X[0])):\n",
        "  X[:, i] = Le.fit_transform(X[:, i])\n",
        "print(X)\n",
        "\n",
        "#converting the data (y) using mapping to apply KNN\n",
        "label_mapping = {\n",
        "    'unacc':0,\n",
        "    'acc':1,\n",
        "    'good':2,\n",
        "    'vgood':3\n",
        "}\n",
        "y['class'] = y['class'].map(label_mapping)\n",
        "y = np.array(y)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_4s5Cs1f7bj",
        "outputId": "02a0a8e7-1a9d-47ee-e8e5-9a39a22ea213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3 3 1]\n",
            " [3 3 2]\n",
            " [3 3 0]\n",
            " ...\n",
            " [1 1 1]\n",
            " [1 1 2]\n",
            " [1 1 0]]\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [2]\n",
            " [3]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATING OUR MODEL\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors= 25, weights= 'uniform')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "prediction = knn.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, prediction)\n",
        "print(\"predictions: \", prediction)\n",
        "print(\"accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLL09XGagiPl",
        "outputId": "af180ae8-3844-42f6-9ca8-b8f3554597c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions:  [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 1 1 0 0 2 1 0 0 1 1 0 1 1 1 0 0 0 1 0 0\n",
            " 0 1 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0\n",
            " 0 0 3 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 2 1 0 0 0 0 1\n",
            " 2 1 2 1 3 1 0 0 0 2 1 0 0 0 3 0 0 3 0 1 1 0 1 0 0 0 0 0 2 0 0 1 0 0 1 1 0\n",
            " 1 1 1 0 0 0 0 0 1 0 0 3 0 0 0 3 3 0 0 0 1 0 0 1 2 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 2 1 0 1 0 1 0 0 2 1 2 0 2 0 1 0 0 1 2 0 1 0 0 0 0 0 2 0 0 0\n",
            " 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 1 1 0 0 0 3 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n",
            " 1 2 0 0 1 0 1 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
            " 3 0 0 1 0 0 0 2 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 2 0 0 0 0 3\n",
            " 1 0 1 0 0 0 3 0 0 0 2 0 0]\n",
            "accuracy:  0.7543352601156069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#testing for a spefic case:\n",
        "a = 1727\n",
        "print(\"actual value: \", y[a])\n",
        "print(\"predicted value: \", knn.predict(X)[a])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1eTbdBYgpQm",
        "outputId": "d9e3b501-a642-4378-9972-abc2a12ce616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actual value:  [3]\n",
            "predicted value:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No código de visualização a parte, coloco também de forma prática a diferença de precisão entre usar na função de KNN  os pesos `uniform` e `distance`, que podem determinar a escolha de qual algoritmo o usuário queira utilizar a depender do sistema analisado."
      ],
      "metadata": {
        "id": "S2slzGR-6AFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine - SVM\n",
        "\n",
        "- Tem interesse em visualizar o que estamos falando nessa sessão? rode `/spyder/programs/SVM_iris_plotting.py`\n",
        "\n",
        "> support-vector machines (SVMs, also support-vector networks) são modelos de aprendizado supervisionado com algoritmos de aprendizado associados que analisam dados para classificação e análise de regressão (Algoritmos matemáticos mais sofisticados que o mapeamento de proximidade que fizemos com KNN). \n",
        "\n",
        "*  Nesta página da documentação oficial: https://scikit-learn.org/stable/modules/svm.html - é possivel ter acesso a diversos exemplos de aplicação assim como exlpicações dos formalismos matemáticos do algoritmo. \n",
        "\n",
        "Uma SVM constrói um hiperplano ou conjunto de hiperplanos em um espaço dimensional alto ou infinito, que pode ser usado para classificação, regressão ou outras tarefas. Intuitivamente, uma boa separação é alcançada pelo hiperplano que possui a maior distância para os pontos de dados de treinamento mais próximos de qualquer classe (a chamada margem funcional), *pois em geral quanto maior a margem menor o erro de generalização do classificador*. \n",
        "\n",
        "Existem Amostras ditas linearmente separáveis, e amostras ditas \"polinomialmente\" separáveis. Em geral, quando o problema não é linearmente separável, os vetores de suporte são as amostras dentro dos limites das margens. \n",
        "\n",
        "- Prós: \n",
        "  - Funciona muito bem com margem de separação clara. \n",
        "  - É eficaz nos casos em que o número de dimensões é maior que o número de amostras.\n",
        "  - Ele usa um subconjunto de pontos de treinamento na função de decisão (chamados de vetores de suporte), portanto, também é eficiente em termos de memória.\n",
        "\n",
        "- Contras:\n",
        "  - Não tem um bom desempenho quando temos um grande conjunto de dados porque o tempo de treinamento necessário é grande. \n",
        "  - Ele também não funciona muito bem quando o conjunto de dados tem mais ruído, ou seja, as classes de destino estão sobrepostas.\n",
        "\n",
        "\n",
        "Vamos aplicar a função SVM que vem imbutida na nossa lib .scikit-learn, utilizando o dataset da iris que usamos para entender o split de treino anteriormente:  "
      ],
      "metadata": {
        "id": "FoHd8Cqbg6ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "#split in features and labels\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "classes = ['Iris Setosa', 'Iris Versicolour', 'Iria Virginica']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "model =  svm.SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(model)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, predictions)\n",
        "print('predictions: ', predictions)\n",
        "print('actual value:', y_test)\n",
        "print('accuracy: ', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwIXFlm1x61T",
        "outputId": "d8310322-7917-4e35-d1f5-fcab393b466e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC()\n",
            "predictions:  [1 1 0 0 2 0 2 0 0 1 2 0 0 1 0 2 2 2 1 1 0 2 0 2 2 2 0 1 2 1]\n",
            "actual value: [1 1 0 0 2 0 2 0 0 1 2 0 0 1 0 2 1 1 1 1 0 2 0 2 2 2 0 1 2 1]\n",
            "accuracy:  0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precisão da utilização de SVM é nitidamente absurdamente boa!!! Comparando o desempenho que obtivemos agora com o modelo anterior, fica claro a diferença de aplicabilidade dado a eficiência.\n",
        "\n",
        "Perceba que podemos analisar individualmente os nomes(classes) preditos pelo nosso modelo em cada iteração simplesmente iterando e observando as classes atribuidas a label do nosso modelo: "
      ],
      "metadata": {
        "id": "2uQDla6H3ORf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(predictions)):\n",
        "  print(classes[predictions[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6JaN8m93eKC",
        "outputId": "991bf0d4-09d6-473a-d475-36294d23c36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iria Virginica\n",
            "Iris Setosa\n",
            "Iris Setosa\n",
            "Iria Virginica\n",
            "Iria Virginica\n",
            "Iria Virginica\n",
            "Iris Versicolour\n",
            "Iria Virginica\n",
            "Iria Virginica\n",
            "Iris Setosa\n",
            "Iria Virginica\n",
            "Iris Setosa\n",
            "Iris Versicolour\n",
            "Iris Versicolour\n",
            "Iris Versicolour\n",
            "Iris Setosa\n",
            "Iris Setosa\n",
            "Iris Setosa\n",
            "Iris Setosa\n",
            "Iris Versicolour\n",
            "Iris Setosa\n",
            "Iris Setosa\n",
            "Iris Versicolour\n",
            "Iris Setosa\n",
            "Iris Versicolour\n",
            "Iria Virginica\n",
            "Iris Versicolour\n",
            "Iris Versicolour\n",
            "Iris Versicolour\n",
            "Iris Setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos também visualizar de forma efetiva diversos tipos de SVM diferentes em um formato comparativo no mesmo sistema que acabamos de tratar, de forma a perceber as sutilezas e particularidades de cada um deles.\n",
        "\n",
        "Vamos executar a seguinte celula no intuito de observar a separação Linear das amostras e da máquina, assim como polinomial e a famosa RBF (a mais precisa e padrão do modelo, que rodou quando executamos o código acima)"
      ],
      "metadata": {
        "id": "FJlFEf0B3Rif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.inspection import DecisionBoundaryDisplay\n",
        "\n",
        "\n",
        "# import some data to play with\n",
        "iris = datasets.load_iris()\n",
        "# Take the first two features. We could avoid this by using a two-dim dataset\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "\n",
        "# we create an instance of SVM and fit out data. We do not scale our\n",
        "# data since we want to plot the support vectors\n",
        "C = 1.0  # SVM regularization parameter\n",
        "models = (\n",
        "    svm.SVC(kernel=\"linear\", C=C),\n",
        "    svm.LinearSVC(C=C, max_iter=10000),\n",
        "    svm.SVC(kernel=\"rbf\", gamma=0.7, C=C),\n",
        "    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C),\n",
        ")\n",
        "models = (clf.fit(X, y) for clf in models)\n",
        "\n",
        "# title for the plots\n",
        "titles = (\n",
        "    \"SVC with linear kernel\",\n",
        "    \"LinearSVC (linear kernel)\",\n",
        "    \"SVC with RBF kernel\",\n",
        "    \"SVC with polynomial (degree 3) kernel\",\n",
        ")\n",
        "\n",
        "# Set-up 2x2 grid for plotting.\n",
        "fig, sub = plt.subplots(2, 2)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
        "\n",
        "X0, X1 = X[:, 0], X[:, 1]\n",
        "\n",
        "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
        "    disp = DecisionBoundaryDisplay.from_estimator(\n",
        "        clf,\n",
        "        X,\n",
        "        response_method=\"predict\",\n",
        "        cmap=plt.cm.coolwarm,\n",
        "        alpha=0.8,\n",
        "        ax=ax,\n",
        "        xlabel=iris.feature_names[0],\n",
        "        ylabel=iris.feature_names[1],\n",
        "    )\n",
        "    ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "    ax.set_title(title)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g4n8-K0H2w0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](https://scikit-learn.org/stable/_images/sphx_glr_plot_iris_svc_001.png)"
      ],
      "metadata": {
        "id": "5in6i5I22x9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression \n",
        "- Tem interesse em visualizar o que estamos falando nessa sessão? rode `/spyder/programs/lin_reg_plot.py`\n",
        "\n",
        "A análise de **Regressão Linear** é um método estatístico utilizado para investigar a relação existente entre variáveis, sendo essas variáveis chamadas de **variáveis dependentes** e **variáveis independentes**. Essa análise é realizada através da construção de uma equação, a qual vamos chamar daqui pra frente de modelo. Esse modelo, vai associar a variável dependente à variável independente e recebe a denominação de **Modelo de Regressão Linear Simples (MRLS)**. No MRLS vamos estudar a relação linear entre duas variáveis quantitativas, ou seja, iremos assumir uma relação causal entre duas variáveis contínuas.\n",
        "\n",
        "Essa análise pode ser usada, por exemplo, para descrever a relação entre variáveis para entender um processo ou fenômeno, para prever o valor de uma variável a partir do conhecimento dos valores das outras variáveis, para substituir a medição de uma variável pela observação dos valores de outras variáveis, e para controlar os valores de uma variável em uma faixa de interesse. \n",
        "\n",
        "Para se estimar o valor esperado, usa-se de uma equação, que determina a relação entre ambas as variáveis.[[1]](https://pt.wikipedia.org/wiki/Regress%C3%A3o_linear)\n",
        "\n",
        "$$y_i = \\alpha + \\beta X_i + \\epsilon_i ,$$ \n",
        "\n",
        "onde $y_i$ é a variável explicada (dependente); representa o que o modelo tentará prever. $\\alpha$ é uma constante, que representa a interceptação da reta com o eixo vertical, $\\beta$ representa a inclinação (coeficiente angular) em relação à variável explicativa e $X_i$ a variável explicativa (independente).\n",
        "\n",
        "$\\epsilon_i$ Representa todos os factores residuais mais os possíveis erros de medição. O seu comportamento é aleatório, devido à natureza dos factores que encerra. Para que essa fórmula possa ser aplicada, os erros devem satisfazer determinadas hipóteses, que são: terem distribuição normal, com a mesma variância ($\\sigma^2$) independentes e independentes da variável explicativa $X$.\n",
        "\n",
        "Para a análise nessa sessão, iremos utilizar um dataset com dados de habitação no estado de Boston ([boston housing data](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) ) Visto a grande variabilidade de parâmetros que estão disponíveis nesse data set e seu nível de detalhes. A disposição de dados no mesmo está na seguinte forma: \n",
        "\n",
        "* Variáveis: existem 14 atributos em cada case do dataset. Eles são:\n",
        "  * CRIM - taxa de criminalidade per capita por cidade\n",
        "\n",
        "  * ZN - proporção de terrenos residenciais zoneados para lotes acima de 25.000 m².\n",
        "\n",
        "  * INDUS - proporção de acres de negócios não varejistas por cidade.\n",
        "\n",
        "  * CHAS - Variável fictícia Charles River (1 se o lugar limita o rio; 0 caso contrário)\n",
        "\n",
        "  * NOX - concentração de óxidos nítricos (partes por 10 milhões)\n",
        "\n",
        "  * RM - número médio de cômodos por domicílio\n",
        "\n",
        "  * IDADE - proporção de unidades ocupadas pelos proprietários construídas antes de 1940\n",
        "\n",
        "  * DIS - distâncias ponderadas para cinco centros de emprego de Boston\n",
        "\n",
        "  * RAD - índice de acessibilidade às rodovias radiais\n",
        "\n",
        "  * IMPOSTO - taxa de imposto de propriedade de valor total por $ 10.000\n",
        "\n",
        "  * PTRATIO - relação aluno-professor por cidade\n",
        "\n",
        "  * B - 1000(Bk - 0,63)^2 onde Bk é a proporção de negros por cidade\n",
        "\n",
        "  * LSTAT - % menor status da população\n",
        "\n",
        "  * MEDV - Valor médio das casas ocupadas pelos proprietários em $ 1.000\n",
        "\n",
        "Assim como o dataset das flores `iris = datasets.load_iris()`, não é necessário fazer download do dataset boston pois o mesmo já está disposto como data test dentro do modulo do scikit-learn, faremos então apenas `boston = datasets.load_boston()` assim como fizemos antes. \n",
        "\n",
        "Primeiro, vamos exportar os datos e analisar o tamanh0/formato do dataset: "
      ],
      "metadata": {
        "id": "YYn4dkVe4YrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "boston = datasets.load_boston()\n",
        "\n",
        "#features / labels\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "print(\"X: \", X)\n",
        "print(\"X_shape: \", X.shape)\n",
        "print(\"y: \", y)\n",
        "print(\"y_shape: \", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DlT2tzYDInW",
        "outputId": "fdd49c69-4b68-4533-e861-e167621278e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:  [[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
            " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
            " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
            " ...\n",
            " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
            " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
            " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n",
            "X_shape:  (506, 13)\n",
            "y:  [24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
            " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
            " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
            " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
            " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
            " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
            " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
            " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
            " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
            " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
            " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
            " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
            " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
            " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
            " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
            " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
            " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
            " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
            " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
            " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
            " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
            " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
            " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
            " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
            " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
            " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
            " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
            " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
            "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
            " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
            " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
            " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
            " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
            " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
            " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
            "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
            " 22.  11.9]\n",
            "y_shape:  (506,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos criar então o nosso modelo e analisar a disposição dos nossos dados em formato de plot scatter"
      ],
      "metadata": {
        "id": "YvRhGjH9Hrzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model / algorithm\n",
        "l_reg = linear_model.LinearRegression()\n",
        "\n",
        "plt.scatter(X.T[5], y, s = 4)\n",
        "plt.ylabel('y label features')\n",
        "plt.xlabel('X label features')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "SXhkoiXOHZ5A",
        "outputId": "4b0274cd-2584-46c0-f32d-f4a587302ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Procedendo como antes, vamos separar nossos dados em dados de teste e dados de treino poara o modelo, e executar nosso treino"
      ],
      "metadata": {
        "id": "KX_pwx-MIwTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the data \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "#training\n",
        "model  =l_reg.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print('Predictions: ', predictions)\n",
        "print('R^2 value: ', l_reg.score(X,y))\n",
        "print('coefficient factor: ', l_reg.coef_)\n",
        "print('intercept: ', l_reg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZEPD8sHHbvQ",
        "outputId": "41a7c03b-b04b-4ef6-a401-55932bcf3b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions:  [16.55256228 14.22260089 43.90228099 24.2114291  20.01629562 29.12068629\n",
            " 20.32940744 24.84839444 15.66801454 13.88662754 18.93600328 12.86369388\n",
            " 12.9482996  19.23637543 20.12192485 33.26110986 23.5449435  16.23684864\n",
            " 26.84139265 25.30847368 20.62173363 36.11267743 22.67795875 17.34972679\n",
            " 21.68566421 22.79822271 24.60299286 18.44510918 20.28327194 31.05869241\n",
            " 28.30633591 35.75513799 32.51275556 17.67511297 30.95806376 28.50113425\n",
            " 20.39006374 23.66287179 35.22517546 39.95357977 32.03293872 17.15402451\n",
            " 17.6091892  24.81426168 20.65716863 25.1893069  10.67681139 32.7102683\n",
            " 38.80586387 20.22135231 40.36293657 19.93603384  8.28688989 22.21109567\n",
            " -4.50124627  4.48650085 28.7044469  19.33907857 19.92913928 23.73308261\n",
            " 34.60527563 20.46214861 30.67796849 16.85514817 12.66487759  6.70405245\n",
            " 25.64325284 42.09466247 17.6389036  24.17382446 19.54345978 38.96864313\n",
            " 13.01917409 25.3609341   4.41269239 27.77095379 28.44560938 27.55788422\n",
            " 24.07922869  5.51266819 21.65778172 23.99983476 24.95382315 13.65545685\n",
            " 37.73014262 34.4144241  24.20338257 23.11960841 25.4324141  29.30322805\n",
            " 27.10394049 18.93041217  8.75481112 19.32964307 20.55777493 26.96774946\n",
            " 13.18403262 20.66430198 27.01899807 20.76456796 26.09853551 20.24467632]\n",
            "R^2 value:  0.7390484735880978\n",
            "coefficient factor:  [-1.29927785e-01  4.57314038e-02  4.21907195e-02  2.40163544e+00\n",
            " -2.14421569e+01  3.33148498e+00  5.87773418e-03 -1.48467420e+00\n",
            "  3.19870861e-01 -1.18069417e-02 -1.01234772e+00  8.81500521e-03\n",
            " -5.38567270e-01]\n",
            "intercept:  42.131402168572436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_test.T[5], y_test, s = 4, label = 'data points')\n",
        "plt.scatter(X_test.T[5], predictions, color=\"black\", s = 4, label = 'model predictions')\n",
        "plt.ylabel('y label features')\n",
        "plt.xlabel('X label features')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "69HNSuMTOPDb",
        "outputId": "13b8f8ab-5963-429d-e29e-0c267cf701cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Qual a diferença entre análise de Regressão Linear e análise de Regressão Logística?\n",
        "\n",
        "Enquanto na Regressão Linear temos uma variável resposta contínua, na **Regressão Logística** nossa variável resposta é **binária**, 0 ou 1, sim ou não. Essa análise é, normalmente, utilizada quando se quer medir a relação de uma variável dependente binária com uma ou mais variáveis independentes, sendo que as independentes tanto podem ser categóricas ou não.\n",
        "\n",
        "A Regressão Logística é uma análise que nos permite estimar a probabilidade associada à ocorrência de determinado evento em face de um conjunto de variáveis explanatórias. As vantagens desse tipo de regressão incluem: \n",
        "\n",
        "(a) facilidade para lidar com variáveis independentes categóricas;\n",
        "\n",
        "(b) fornece resultados em termos de probabilidade; \n",
        "\n",
        "(c) facilidade de classificação de indivíduos em categorias; \n",
        "\n",
        "(d) requer pequeno número de suposições;  \n",
        "\n",
        "(e) possui alto grau de confiabilidade.\n",
        "\n",
        "Refs e mais material para ler:\n",
        "\n",
        "- [Regressão Logística](https://pt.wikipedia.org/wiki/Regress%C3%A3o_log%C3%ADstica)\n",
        "\n",
        "- [Função Logística](https://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_log%C3%ADstica)\n",
        "\n"
      ],
      "metadata": {
        "id": "7o_S7IywU29k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Algoritmos de Clustering\n",
        "\n",
        "Os algoritmos de agrupamento, também conhecidos como clustering, fazem parte do que é conhecido como aprendizado de máquina não supervisionado. Isto quer dizer que, a partir de dados “gerais” e sem nenhuma “anotação”, é possível descobrir alguns padrões e criar um modelo que, na prática, vai ser utilizado para classificar um novo conjunto de dados quando ele surgir.\n",
        "\n",
        "Por exemplo, vamos supor que desejamos classificar clientes em grupos. Os algoritmos de clustering vão analisar os dados e gerar regras internas para dizer se um cliente X pertence a um grupo A, B ou qualquer que seja.\n",
        "\n",
        "Entretanto, nem sempre podemos apresentar uma descrição significativa e representativa do grupo A ou B, pois mesmo tendo acesso a definição das regras que colocam ou não um dado no grupo, fica complicado caracterizá-lo. Às vezes, fica fácil dizer algo como “este é o grupo do clientes AAA” ou “esta imagem é mais parecida com as imagens que possuem gatos”. Não obstante, quando falamos em conjuntos de dados com muitos atributos, fica complicado atribuir significado aos grupos, que também são chamados de clusters. Esta é uma característica dos algoritmos não supervisionados de clustering: como os padrões são detectados automaticamente nem sempre podemos facilmente explicar o que foi gerado.\n",
        "\n",
        "### O algoritmo de K-means\n",
        "\n",
        "K-Means é um algoritmo de clusterização (ou agrupamento) de aprendizado não supervisionado (ou seja, que não precisa de inputs de confirmação externos) que avalia e clusteriza os dados de acordo com suas características, como {lojas/centro logistico}, {clientes/produtos ou serviços semelhantes}, {séries/gênero da série ou faixa etaria}, {paciente/sintoma ou característica semelhante} etc.\n",
        "\n",
        "* Como funciona? \n",
        " \n",
        "1 - Primeiro, preciso definir um ‘K’, ou seja, um número de clusters (ou agrupamentos).\n",
        "\n",
        "2 - Depois, preciso definir, aleatoriamente, um centroide para cada cluster.\n",
        "\n",
        "3 - O próximo passo é calcular, para cada ponto, o centroide de menor distância. Cada ponto pertencerá ao centroide geométricamente mais próximo a ele.\n",
        "\n",
        "4 - Agora, devo reposicionar o centróide. A nova posição do centroide deve ser a média da posição de todos os pontos do cluster.\n",
        "\n",
        "5 - Os dois ultimos passos são repetidos, iterativamente, até obtermos a posição ideal dos centróides.\n",
        "\n",
        "\n",
        "Para visualziar um pouco melhor o desempenho desse algoritmo, vamos utilizar mais uma vez um dataset de treino imbutido do modulo scikit_learn, agora o nosso dataset irá tratar de dados relacionados a cancer de mama, através de `bc = datasets.load_breast_cancer()`"
      ],
      "metadata": {
        "id": "_JcDh7ErYgXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import scale\n",
        "import pandas as pd\n",
        "\n",
        "bc = datasets.load_breast_cancer() \n",
        "print(bc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoKMrhylwgXG",
        "outputId": "e33a9edf-f8b7-4bc1-8fb6-f09e8cc957fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
            "        1.189e-01],\n",
            "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
            "        8.902e-02],\n",
            "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
            "        8.758e-02],\n",
            "       ...,\n",
            "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
            "        7.820e-02],\n",
            "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
            "        1.240e-01],\n",
            "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
            "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
            "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
            "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
            "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
            "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
            "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
            "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
            "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
            "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
            "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
            "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
            "       'smoothness error', 'compactness error', 'concavity error',\n",
            "       'concave points error', 'symmetry error',\n",
            "       'fractal dimension error', 'worst radius', 'worst texture',\n",
            "       'worst perimeter', 'worst area', 'worst smoothness',\n",
            "       'worst compactness', 'worst concavity', 'worst concave points',\n",
            "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'breast_cancer.csv', 'data_module': 'sklearn.datasets.data'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De antemão, olhando separadamernte para nossos dados:"
      ],
      "metadata": {
        "id": "nslrg1hWxfMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = bc.data\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaN_bFgKxOWh",
        "outputId": "80a2ab79-b187-4975-8818-bc9fb25b68d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceba que os números dos nossos dados são muito grandes/pequenos, e existe uma diferença enorme entre eles, então vamos reescalonar eles para ajudar mais o nosso algoritmo"
      ],
      "metadata": {
        "id": "MYpWx6GlxxhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = scale(bc.data)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7RcBE36x6Vq",
        "outputId": "2ebc2112-23e1-4754-89ca-9bf4b249ec66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.09706398 -2.07333501  1.26993369 ...  2.29607613  2.75062224\n",
            "   1.93701461]\n",
            " [ 1.82982061 -0.35363241  1.68595471 ...  1.0870843  -0.24388967\n",
            "   0.28118999]\n",
            " [ 1.57988811  0.45618695  1.56650313 ...  1.95500035  1.152255\n",
            "   0.20139121]\n",
            " ...\n",
            " [ 0.70228425  2.0455738   0.67267578 ...  0.41406869 -1.10454895\n",
            "  -0.31840916]\n",
            " [ 1.83834103  2.33645719  1.98252415 ...  2.28998549  1.91908301\n",
            "   2.21963528]\n",
            " [-1.80840125  1.22179204 -1.81438851 ... -1.74506282 -0.04813821\n",
            "  -0.75120669]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dando continuidade, assim como já fizemos recursivamente em outros métodos até aqui, "
      ],
      "metadata": {
        "id": "yGEeNp0qzDFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = bc.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "model = KMeans(n_clusters = 2, random_state = 0)\n",
        "\n",
        "model.fit(X_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "labels = model.labels_\n",
        "\n",
        "print('labels: ', labels)\n",
        "print('predictions: ', predictions)\n",
        "print('accuracy: ', accuracy_score(y_test, predictions))\n",
        "print('actual: ', y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5s00Y9GzJBZ",
        "outputId": "09bb28f5-e54c-43e6-fdec-ca390f0f3364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  [1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0\n",
            " 1 1 1 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 1 1 0 0 1 0 1\n",
            " 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 0 0 0 1\n",
            " 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1\n",
            " 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1\n",
            " 0 1 1 1 1 1 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 0\n",
            " 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1\n",
            " 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1\n",
            " 0 0 1 1 0 0 1 0 1 0 1]\n",
            "predictions:  [1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 0 1]\n",
            "accuracy:  0.9298245614035088\n",
            "actual:  [1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1\n",
            " 0 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1\n",
            " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
            " 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rodando várias vezes fica notável o viés binário de acurácia que sujeitamos o algoritmo por dar apenas 0/1 sem labels, no intuito então de tentar melhora isso, faremos o seguinte"
      ],
      "metadata": {
        "id": "m7nR44d_1DPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.crosstab(y_train, labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7u2YKLI1S8h",
        "outputId": "258aecd7-26e6-40b6-c72a-6db344f0e9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "col_0    0    1\n",
            "row_0          \n",
            "0      138   32\n",
            "1       16  269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apenas a nível de visualização e também de informação, para apresentar uma forma interessante de obter dados de testes para clusters, vamos utilizar agora um pacote do [módulo de  geração de conjuntos de dados](https://scikit-learn.org/stable/datasets/sample_generators.html#sample-generators) do scikit-learn, especificamente o [`sklearn.datasets.make_blobs`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs)\n",
        "\n",
        "A ideia aqui vai ser criar 3 centros de blobs aletórios em [[1, 1], [-1, -1], [1, -1]] e preencher blobs de dados ao redor deles, e separar esses blobs através do método de K-Means, no intuito de plotar um gráfico que deixe clara a separaçào feita usando um sistema de cores pré definida."
      ],
      "metadata": {
        "id": "oqOUguSL5ga_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_blobs\n",
        "import time\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#GENERATING DATA\n",
        "np.random.seed(0)\n",
        "\n",
        "batch_size = 45\n",
        "centers = [[1, 1], [-1, -1], [1, -1]]\n",
        "n_clusters = len(centers)\n",
        "X, labels_true = make_blobs(n_samples=3000, centers=centers, cluster_std=0.7)\n",
        "\n",
        "#CLUSTERING WITH KMEANS\n",
        "k_means = KMeans(init=\"k-means++\", n_clusters=3, n_init=10)\n",
        "t0 = time.time()\n",
        "k_means.fit(X)\n",
        "t_batch = time.time() - t0\n",
        "\n",
        "fig = plt.figure(figsize=(8, 3))\n",
        "fig.subplots_adjust(left=0.02, right=2, bottom=0.05, top=1.2)\n",
        "colors = [\"blue\", \"orange\", \"green\"]\n",
        "\n",
        "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
        "\n",
        "k_means_cluster_centers = k_means.cluster_centers_\n",
        "k_means_labels = pairwise_distances_argmin(X, k_means_cluster_centers)\n",
        "\n",
        "# PLOTTING THE RESULT\n",
        "ax = fig.add_subplot(1, 3, 1)\n",
        "for k, col in zip(range(n_clusters), colors):\n",
        "    my_members = k_means_labels == k\n",
        "    cluster_center = k_means_cluster_centers[k]\n",
        "    ax.plot(X[my_members, 0], X[my_members, 1], \"w\", markerfacecolor=col, marker=\".\")\n",
        "    ax.plot(\n",
        "        cluster_center[0],\n",
        "        cluster_center[1],\n",
        "        \"o\",\n",
        "        markerfacecolor=col,\n",
        "        markeredgecolor=\"k\",\n",
        "        markersize=6,\n",
        "    )\n",
        "ax.set_title(\"KMeans\")\n",
        "#ax.set_xticks(())\n",
        "#ax.set_yticks(())\n",
        "plt.text(-3.5, 1.8, \"train time: %.2fs\\ninertia: %f\" % (t_batch, k_means.inertia_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "xD7ooDW_3amS",
        "outputId": "6634f291-d4bd-451e-dadb-631c5d140000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(-3.5, 1.8, 'train time: 0.27s\\ninertia: 2470.584849')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks \n",
        " \n",
        "Inspirando-se no funcionamento dos neurônios biológicos do sistema nervoso dos animais, estabeleceu-se na área da Inteligência Artificial um modelo computacional de um neurônio conforme ilustrado a seguir: \n",
        "\n",
        "![image.png](https://miro.medium.com/max/1128/1*KDiqpWOgtCnO8x3wZJHmDA.png) \n",
        "\n",
        "Os sinais da entrada no neurônio são representados pelo vetor $x = [x_1, x_2, x_3, …, x_N]$, podendo corresponder aos pixels de uma imagem, por exemplo. Ao chegarem ao neurônio, são multiplicados pelos respectivos **pesos sinápticos**, que são os elementos do vetor $w = [w_1, w_2, w_3, …, w_N]$, gerando o valor $z$, comumente denominado **potencial de ativação**, de acordo com a expressão:\n",
        "\n",
        "$$ z = \\sum_{i=1}^{N} x_i w_i + b $$\n",
        "\n",
        "O termo adicional $b$ provê um grau de liberdade a mais, que não é afetado pela entrada nessa expressão, correspondendo tipicamente ao “bias” (viés). O valor $z$ passa então por uma função matemática de ativação $\\sigma$, com a característica de ser não linear, responsável por limitar tal valor a um certo intervalo, produzindo o valor final de saída $y$ do neurônio. Algumas funções de ativação usadas são a degrau, sigmoide, tangente hiperbólica, softmax e ReLU (Rectified Linear Unit)\n",
        "\n",
        "### Criando camadas de neurônios \n",
        "\n",
        "Com apenas um neurônio não se pode fazer muita coisa, mas podemos combiná-los em uma estrutura de camadas, cada uma com número diferente de neurônios, formando uma rede neural denominada **Perceptron Multicamadas** (“Multi Layer Perceptron — MLP”). O vetor de valores de entrada $x$ passa pela camada inicial, cujos valores de saída são ligados às entradas da camada seguinte, e assim por diante, até a rede fornecer como resultado os valores de saída da última camada. Pode-se arranjar a rede em várias camadas, tornando-a profunda e capaz de aprender relações cada vez mais complexas.\n",
        "\n",
        "![image.png](https://miro.medium.com/max/1316/1*H61ieko1YyHzqBNZTzz7IQ.png) \n",
        "\n",
        "### Treinamento \n",
        "\n",
        "Para que uma rede dessas funcione, é preciso treiná-la. É como ensinar a uma criança o beabá. O treinamento de uma rede MLP insere-se no contexto de **aprendizado de máquina supervisionado**, em que cada amostra de dados utilizada apresenta um rótulo informando a que classificação ela se encaixa. Por exemplo, uma imagem de um cachorro contém um rótulo informando que aquilo é um cachorro. Assim, a ideia geral é fazer com que a rede aprenda os padrões referentes a cada tipo de coisa (cada *classe*), assim, quando uma amostra desconhecida for fornecida à rede, ela seja capaz de estabelecer a qual classe tal amostra pertence. Como isso pode ser feito?\n",
        "\n",
        "* **Overfitting e Underfitting**\n",
        "\n",
        "Como mencionamos antes, a incapacidade de um modelo de capturar a verdadeira relação entre variáveis e o objeto a ser predito é o que chamamos de VIÉS (Bias em inglês). Então, quando o erro de viés é alto significa que o modelo não está aprendendo nada.\n",
        "\n",
        "Por outro lado, se há um viés muito pequeno o modelo fica tão ajustado aos dados de treinamento que quando é usado com dados diferentes acaba errando muito. Aqui entra o conceito de variância.\n",
        "\n",
        "![image.png](https://miro.medium.com/max/396/1*q_hdLouaSQwUkshCe5rY4Q.png)\n",
        "\n",
        "Nessa imagem temos a linha azul como sendo o nosso modelo onde queremos separar esse dataset em duas categoriais. Veja que há muitos X vermelhos juntos com as bolinhas, as categorias não foram muito bem separadas, isso significa que o modelo ainda não entendeu a “curva” que ele deveria fazer para categorizar esses dados corretamente. Chamamos isso de Underfitting.\n",
        "\n",
        "A variância é a sensibilidade de um modelo ao ser usado com outros datasets diferentes do treinamento. Se o modelo é muito sensível aos dados de treinamento, ou seja, identificou tão bem a relação entre os dados de treinamento que quando colocado em teste irá errar justamente a variação que existe entre os datasets. Veja na última imagem como o nosso modelo está acertando absolutamente todos os dados. Chamamos isso de Overfitting.\n",
        "\n",
        "![image.png](https://miro.medium.com/max/406/1*QfGXli0jP1QDAUuAeWOTeA.png)\n",
        "\n",
        "O modelo ideal seria então será dado pela curva que melhor representasse os dados de uma forma a encontrar equilibro entre essas duas grandezas aqui apresentadas (viés e variância.). E como podemos encontrar isso?\n",
        "\n",
        "* **Backpropagation** \n",
        "\n",
        "A ideia do algoritmo backpropagation é, com base no **cálculo do erro** ocorrido na camada de saída da rede neural, recalcular o valor dos pesos do vetor $w$ da camada última camada de neurônios e assim proceder para as camadas anteriores, de trás para a frente, ou seja, atualizar todos os pesos $w$ das camadas a partir da última até atingir a camada de entrada da rede, para isso realizando a retropropagação o erro obtido pela rede. Em outras palavras, calcula-se o erro entre o que a rede achou que era e o que de fato era (ex. era um gato e ela achou que era um cachorro), então recalculamos o valor de todos os pesos, começando da última camada e indo até a primeira, sempre tendo em vista diminuir esse erro.\n",
        "\n",
        "O algoritmo pode ser então colocado da seguinte forma: \n",
        "\n",
        "1 - Inicializar todos os pesos da rede com pequenos valores **aleatórios.**\n",
        "\n",
        "2 - Fornecer dados de entrada à rede e calcular o valor da função de erro/de custo obtida (cost function), ao comparar com o valor de saída esperado. Lembre-se de que como o aprendizado é supervisionado, já se sabe de antemão qual deveria ser a resposta correta. É importante que a função de erro seja **diferenciável**.\n",
        "\n",
        "3 - Na tentativa de minimizar o valor da função de erro, calculam-se os valores dos **gradientes** para cada peso da rede. Do Cálculo, sabemos que o vetor gradiente fornece a direção de maior crescimento de uma função; aqui, como queremos caminhar com os pesos na direção de maior decréscimo da função de erro, basta tomarmos o sentido contrário ao do gradiente e…voilà! Já temos um excelente caminho por onde andar.\n",
        "\n",
        "4 - Uma vez que temos o vetor gradiente calculado, atualizamos cada peso de modo **iterativo**, sempre recalculando os gradientes em cada passo de iteração, até o erro diminuir e chegar abaixo de algum limiar preestabelecido, ou o número de iterações atingir um valor máximo, quando enfim o algoritmo termina e a rede está treinada.\n",
        "\n",
        "A formula geral de atualização dos pesos na iteração fica então da seguinte forma: \n",
        "\n",
        "$$ w \\Longleftarrow w - \\eta \\frac{\\partial E}{\\partial w} $$\n",
        "\n",
        "Ou seja, o valor do peso na iteração atual será o valor do peso na iteração anterior, corrigido de valor proporcional ao gradiente. O sinal negativo indica que estamos indo na direção contrária à do gradiente, conforme mencionado. O parâmetro $\\eta$ representa a taxa de aprendizado da rede neural, controlando a tamanho do passo que tomamos na correção do peso.\n",
        "\n",
        "Fontes extras: \n",
        "\n",
        "* https://medium.com/@tiago.tmleite/neural-networks-multilayer-perceptron-and-the-backpropagation-algorithm-a5cd5b904fde\n",
        "\n",
        "* https://medium.com/ensina-ai/redes-neurais-roots-1-introdu%C3%A7%C3%A3o-ffdd6f8b9f01\n",
        "\n",
        "* https://medium.com/ensina-ai/redes-neurais-com-tensorflow-primeiros-passos-20847dd5d27f"
      ],
      "metadata": {
        "id": "a43ApC0nH0lX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN - Convolutional Neural Networks\n",
        "\n",
        "Uma CNN é um tipo específico de rede neural normalmente utilizada para classificação de imagens. Mas para entendermos uma CNN, é preciso compreender como uma imagem é representada computacionalmente.\n",
        "\n",
        "Uma imagem preta e branca (grayscale) é representada como uma matrix 2D, em que cada posição da matrix representa um pixel da imagem. Os valores para cada elemento variam entre 0 (preto) até 255 (branco). Já uma imagem colorida, é normalmente representada por uma matrix 3D de forma que seja possível armazenar uma combinação das cores vermelho, verde e azul (RGB).\n",
        "\n",
        "A ideia principal de uma Rede Convolucional se baseia nisso: filtrar linhas, curvas e bordas e em cada camada acrescida transformar essa filtragem em uma imagem mais complexa. Vamos entender mais detalhadamente nos próximos tópicos.\n",
        "\n",
        "* Entradas\n",
        "\n",
        "Quando falamos em reconhecimento/classificação de imagens, as entradas são usualmente matrizes tridimensionais com altura e largura (de acordo com as dimensões da imagem) e profundidade, determinada pela quantidade de canais de cores. Em geral as imagens utilizam três canais, RGB, com os valores de cada pixel.\n",
        "\n",
        "![image.png](https://miro.medium.com/max/1196/1*VZ2D3BS9avtqzOMvj-9vbQ.png)\n",
        "\n",
        "* Convoluções \n",
        "\n",
        "As convoluções funcionam como filtros que enxergam pequenos quadrados e vão “escorregando” por toda a imagem captando os traços mais marcantes. Explicando melhor, com uma imagem 32x32x3 e um filtro que cobre uma área de 5x5 da imagem com movimento de 2 saltos (chamado de `stride`), o filtro passará pela imagem inteira, por cada um dos canais, formando no final um feature map ou activation map de 28x28x1.\n",
        "\n",
        "A profundidade da saída de uma convolução é igual a quantidade de filtros aplicados. Quanto mais profundas são as camadas das convoluções, mais detalhados são os traços identificados com o activation map.\n",
        "\n",
        "O filtro, que também é conhecido por `kernel`, é formado por pesos inicializados aleatoriamente, atualizando-os a cada nova entrada durante o processo de backpropagation. A pequena região da entrada onde o filtro é aplicado é chamada de `receptive field`.\n",
        "\n",
        "Além do tamanho do filtro e o stride da convolução como hiperparâmetro, quem está modelando uma CNN também tem que escolher como será o `padding`. O padding pode ser nenhum, no qual o output da convolução ficará no seu tamanho original, ou zero pad, onde uma borda é adicionada e preenchida com 0's. O padding serve para que as camadas não diminuam muito mais rápido do que é necessário para o aprendizado.\n",
        "\n",
        "![image.png](https://miro.medium.com/max/1004/1*Oj4LnMvcbPRw2P9rf7TAgA.png)\n",
        "\n",
        "* Função de ativação \n",
        "\n",
        "As funções de ativação servem para trazer a não-linearidades ao sistema, para que a rede consiga aprender qualquer tipo de funcionalidade. Há muitas funções, como [sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function), [tanh](https://pt.wikipedia.org/wiki/Tangente_hiperb%C3%B3lica) e [softmax](https://pt.wikipedia.org/wiki/Fun%C3%A7%C3%A3o_log%C3%ADstica), mas a mais indicada para redes convolucionais é a [Relu](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) por ser mais eficiente computacionalmente sem grandes diferenças de acurácia quando comparada a outras funções. Essa função zera todos os valores negativos da saída da camada anterior.\n",
        "\n",
        "* Pooling \n",
        "\n",
        "Uma camada de pooling serve para simplificar a informação da camada anterior. Assim como na convolução, é escolhida uma unidade de área, por exemplo 2x2, para transitar por toda a saída da camada anterior. A unidade é responsável por resumir a informação daquela área em um único valor. Se a saída da camada anterior for 24x24, a saída do pooling será 12x12. Além disso, é preciso escolher como será feita a sumarização. O método mais utilizado é o maxpooling, no qual apenas o maior número da unidade é passado para a saída. Essa sumarização de dados serve para diminuir a quantidade de pesos a serem aprendidos e também para evitar overfitting.\n",
        "\n",
        "![image.png](https://miro.medium.com/max/1400/1*WvHC5bKyrHa7Wm3ca-pXtg.gif)\n",
        "\n",
        "Ao final da rede é colocada uma camada Fully connected, onde sua entrada é a saída da camada anterior e sua saída são N neurônios, com N sendo a quantidade de classes do seu modelo para finalizar a classificação.\n",
        "\n",
        "\n",
        "\n",
        "Material Suplementar: \n",
        "\n",
        "* https://medium.com/data-hackers/uma-introdu%C3%A7%C3%A3o-as-redes-neurais-convolucionais-utilizando-o-keras-41ee8dcc033e\n",
        "\n",
        "* https://medium.com/neuronio-br/entendendo-redes-convolucionais-cnns-d10359f21184\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Convolutional_neural_network"
      ],
      "metadata": {
        "id": "tMtJwXIpFA6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para testar um pouco mais os últimos assuntos explicados, vamos criar uma rede neural, especificamente uma convolucional, no intuito de ser capaz de reconhecer digitos numéricos escritos a mão. \n",
        "\n",
        "Vamos começar exportando um dataset especificamente criado para essa tarefa, que é muito utilizado no meio de trabalho de CNN. \n",
        "\n",
        "O [banco de dados MNIST](https://en.wikipedia.org/wiki/MNIST_database) (banco de dados do Instituto Nacional de Padrões e Tecnologia Modificado) é um grande banco de dados de dígitos manuscritos que é comumente usado para treinar vários sistemas de processamento de imagem. O banco de dados também é amplamente utilizado para treinamento e teste na área de aprendizado de máquina. Ele foi criado \"remixando\" as amostras dos conjuntos de dados originais do NIST.\n",
        "\n",
        "Vamos então proceder executando um pip instal desse dataset num formato python friendly, já implementado para essa própria linguagem: "
      ],
      "metadata": {
        "id": "jZuwHKTFkUgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H11_YebSkIXJ",
        "outputId": "c32c47e7-7fb1-4773-afb2-06d29f8c5174"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mnist\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mnist) (1.21.6)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos continuar agora com o código da mesma forma que fizemos com o tratamento e organização de todos os nossos projetos em sklearn até então, identificando o formato do nosso dataset e dividindo ele em parte de treino e parte de teste"
      ],
      "metadata": {
        "id": "viSm3hYbla50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier \n",
        "from sklearn.metrics import confusion_matrix \n",
        "import mnist\n",
        "\n",
        "#TRAINING VARIABLES\n",
        "X_train = mnist.train_images()\n",
        "y_train = mnist.train_labels()\n",
        "\n",
        "X_test = mnist.test_images()\n",
        "y_test = mnist.test_labels()\n",
        "\n",
        "print('X_train', X_train)\n",
        "print('X shape', X_train.shape)\n",
        "\n",
        "print('y_train', y_train)\n",
        "print('y shape', y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHJUvpvGjP1d",
        "outputId": "31bf4396-4909-4402-a78f-72c0a92e796d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train [[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n",
            "X shape (60000, 28, 28)\n",
            "y_train [5 0 4 ... 5 6 8]\n",
            "y shape (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ajustar o formato do array acima fazendo o seguinte: "
      ],
      "metadata": {
        "id": "VY0_jqVfJCg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((-1, 28*28))\n",
        "X_test = X_test.reshape((-1, 28*28))\n",
        "\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p332TbSsnPj9",
        "outputId": "5f36bf82-2e6b-4022-8d06-fb17bb5b7277"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceba que se printarmos uma celula inteira, ela tem valores em um range muito grande, algo característico desse formato de dataset, vamos então (assim como já fizemos antes) renormalizar os dados dentro de 0 e 1"
      ],
      "metadata": {
        "id": "7ek0ftnqJJfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fMTHaUPne-n",
        "outputId": "de23447a-d25e-4635-ce52-30c29d319eac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renormalizando de forma simples:"
      ],
      "metadata": {
        "id": "XfyhRYs-nq_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train/256)\n",
        "X_test = np.array(X_test/256)\n",
        "print(X_train[0])\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnJQhYQTnlB3",
        "outputId": "c4c6c90e-1813-4855-a4fd-83dd247e2b54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01171875 0.0703125  0.0703125  0.0703125\n",
            " 0.4921875  0.53125    0.68359375 0.1015625  0.6484375  0.99609375\n",
            " 0.96484375 0.49609375 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1171875  0.140625   0.3671875  0.6015625\n",
            " 0.6640625  0.98828125 0.98828125 0.98828125 0.98828125 0.98828125\n",
            " 0.87890625 0.671875   0.98828125 0.9453125  0.76171875 0.25\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19140625\n",
            " 0.9296875  0.98828125 0.98828125 0.98828125 0.98828125 0.98828125\n",
            " 0.98828125 0.98828125 0.98828125 0.98046875 0.36328125 0.3203125\n",
            " 0.3203125  0.21875    0.15234375 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.0703125  0.85546875 0.98828125\n",
            " 0.98828125 0.98828125 0.98828125 0.98828125 0.7734375  0.7109375\n",
            " 0.96484375 0.94140625 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3125     0.609375   0.41796875 0.98828125\n",
            " 0.98828125 0.80078125 0.04296875 0.         0.16796875 0.6015625\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0546875  0.00390625 0.6015625  0.98828125 0.3515625\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54296875 0.98828125 0.7421875  0.0078125  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04296875\n",
            " 0.7421875  0.98828125 0.2734375  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13671875 0.94140625\n",
            " 0.87890625 0.625      0.421875   0.00390625 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31640625 0.9375     0.98828125\n",
            " 0.98828125 0.46484375 0.09765625 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.17578125 0.7265625  0.98828125 0.98828125\n",
            " 0.5859375  0.10546875 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0625     0.36328125 0.984375   0.98828125 0.73046875\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.97265625 0.98828125 0.97265625 0.25       0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1796875  0.5078125  0.71484375 0.98828125\n",
            " 0.98828125 0.80859375 0.0078125  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15234375 0.578125\n",
            " 0.89453125 0.98828125 0.98828125 0.98828125 0.9765625  0.7109375\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09375    0.4453125  0.86328125 0.98828125 0.98828125 0.98828125\n",
            " 0.98828125 0.78515625 0.3046875  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.08984375 0.2578125  0.83203125 0.98828125\n",
            " 0.98828125 0.98828125 0.98828125 0.7734375  0.31640625 0.0078125\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.0703125  0.66796875\n",
            " 0.85546875 0.98828125 0.98828125 0.98828125 0.98828125 0.76171875\n",
            " 0.3125     0.03515625 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21484375 0.671875   0.8828125  0.98828125 0.98828125 0.98828125\n",
            " 0.98828125 0.953125   0.51953125 0.04296875 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53125    0.98828125\n",
            " 0.98828125 0.98828125 0.828125   0.52734375 0.515625   0.0625\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "(60000, 784)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, vamos prosseguir para a criação e treino do nosso modelo assim como explicamos até aqui. Antes disso, quero pontuar que para rodar esse tipo de rede neural é interessante utilizar um ambiente de execução integrado com GPU's para otimizar a execução do mesmo em ordens de grandeza de tempo, para fazer isso dentro do próprio ambiente de programação do Google Colab, recomendo ir em \"Ambiente de execução\" (runtime na versão em inglês) >  \"Alterar o tipo do ambiente de execução\" > \"Acelerador de Hardware\" e então selecionar GPU. Após esse procedimento feito, podemos seguir com: \n",
        "\n",
        "PS.: talvez seja necessário importar as bibliotecas novamente após trocar o ambiente de execução"
      ],
      "metadata": {
        "id": "kYiqwhayn4R2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = MLPClassifier(solver='adam', activation='relu', hidden_layer_sizes=(64, 64))\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNVn_i-In3yo",
        "outputId": "5bce276b-d35c-4df7-9b90-6ee486c993f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(64, 64))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De posse do modelo treinado, podemos fazer como antes e calcular a sua acurácia usando os dados que separamos para teste no nosso dataset"
      ],
      "metadata": {
        "id": "XbihSFRMPFSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = clf.predict(X_test)\n",
        "acc = confusion_matrix(y_test, prediction)\n",
        "\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP05kXAIKtzv",
        "outputId": "8098f34f-c1bd-403a-8f99-3ef22c734d86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 966    0    0    1    1    2    4    2    2    2]\n",
            " [   0 1126    2    1    0    1    2    1    2    0]\n",
            " [   3    1 1002    8    4    0    1    5    8    0]\n",
            " [   0    1    4  988    0    7    0    5    3    2]\n",
            " [   1    0    5    0  960    0    5    2    2    7]\n",
            " [   2    0    0   14    1  866    2    0    5    2]\n",
            " [   4    3    1    1    8    8  931    0    2    0]\n",
            " [   0    4    6    2    2    0    0 1007    3    4]\n",
            " [   4    0    3    8    2    4    0    3  945    5]\n",
            " [   3    2    0    4    8    3    0    6    2  981]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceba que dessa vez, devido ao numero diferente de dimensões dos nossos dados obtivemos uma matriz de acurácia - Como esperado!- Podemos então proceder para o cálculo de um valor de acurácia que podemos interpretar melhor seguindo a formula mencionada em nossos materiais suplementares para esse modelo, calculando então o traço da matriz dividido pela soma de todos seus elementos juntos. \n",
        "\n",
        "Para isso, definimos a seguinte função e voilá!"
      ],
      "metadata": {
        "id": "S9ZQFX5PLAY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(cm):\n",
        "  diagonal = cm.trace()\n",
        "  elements = cm.sum()\n",
        "  return diagonal/elements\n",
        "\n",
        "print('model accuracy (%): ', accuracy(acc)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHSTbKBzLEd9",
        "outputId": "0bb7adb9-bebb-4cca-d77e-add4df6ce60d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvando o modelo para não precisar treinar ele novamente em um ambiente de execução dedicado: \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x0H0suXPMrxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib \n",
        "\n",
        "filename = 'cnn_model.sav'\n",
        "joblib.dump(clf,filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_udZYZhRMrV5",
        "outputId": "9bd8b5d8-6610-471b-a317-94b54f698669"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cnn_model.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para abrir o modelo acima novamente sem a necessidade de rodar o fit inteiro novamente, basta executar:"
      ],
      "metadata": {
        "id": "gnwJdVSsN7RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = joblib.load(filename) "
      ],
      "metadata": {
        "id": "sJoUiOORN5a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Você pode agora testar ele por si mesmo! Basta escrever um número no GIMP ou Paint, salvar ele como imagem e transformar essa imagem numa matriz de dados. Podemos inclusive fazer isso através de um simlpes programa em python, perceba \n",
        "\n",
        "```Python\n",
        "from PIL import Image\n",
        "\n",
        "img  = Image.open('name_of_the_image.png')\n",
        "\n",
        "data = list(img.getdata())\n",
        "print(data)\n",
        "```\n",
        "\n",
        "Vai nos dar um array com um base numero alto (eg 255), após isso podemos então pegar esse número e rodar ele novamente no seguinte formato\n",
        "\n",
        "```Python\n",
        "from PIL import Image\n",
        "\n",
        "img  = Image.open('name_of_the_image.png')\n",
        "\n",
        "data = list(img.getdata())\n",
        "for i in range(len(data)):\n",
        "  data[i] = 255 - data[i]\n",
        "print(data)\n",
        "```\n",
        "\n",
        "então podemos utilizar esse array ajustado para avaliar a precisão do nosso modelo \n",
        "\n",
        "\n",
        "```Python\n",
        "number = [data]\n",
        "number = np.array(number)/256\n",
        "\n",
        "p = clf.predict([number])\n",
        "print(p)\n",
        "```"
      ],
      "metadata": {
        "id": "mZVikRgGPw1b"
      }
    }
  ]
}